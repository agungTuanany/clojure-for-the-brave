#+TITLE: Clojure For The Brave and True Part III -- Chapter 9 The Sacred Art Of Concurrent And Parallel Programming
#+DATE: 2025-10-22 Wed
#+AUTHOR: Agung Tuanany
#+DESCRIPTION: Clojure, book, A summary per chapter from book clojure-for-the-brave-and-true.
#+KEYWORDS: programming, clojure, clojure-for-the-brave-and-true.
#+OPTIONS: toc:nil num:nil


If I were the lord of a manor and you were my heir, I would sit you down on your
13th name day and tell you, "The world of computing is changing, lass, and ye
must be prepared for the new world of multi-core processor lest ye be trampled
by it".

"Listen well: in recent years, GPU clock speeds have barely increased, but
dual-core and quad-core computers have become common. The laws of physic are
cruel and absolute, and they demand that increasing clock speed requires
exponentially more power. The realm's best engineers are unlikely to overcome
this limitation anytime soon. If ever. Therefore, you can expect the trend of
increasing cores on a single machine to continue--as will the expectation that
you as programmer will know how to make the most of modern hardware."

"Learning to program in this new paradigm will be fun and fascinating, verily.
But beware: it is also fraught with peril[fn:1]. You must learn /concurrent and
parallel programming/, which is the sacred art of structuring your application
to safely manage multiple, simultaneously executing tasks."

"You begin your instruction in this art with an overview of concurrency and
parallelism concepts. You'll then study the three goblins that harry every
practitioner: reference cells, mutual exclusion, and dwarven bersekers. And
you'll learn three tools that will aid you: futures, promises, and delays."

And then I'd tap you on the shoulder with a keyboard, signaling that you were
ready to begin.

* Concurrency and Parallelism Concepts

Concurrent and parallel programming involves a lot of messy details at all
levels of program execution, from the hardware to the operating system to
programming language libraries to the code that springs from your heart and
lands in your editor. But before you worry your head with any of those details,
in this section I'll walk through the high-level concepts that surround
concurrency and parallelism.

** Managing Multiple Tasks vs. Executing Tasks Simultaneously

/Concurrency/ refers to managing more than one task at the same time. /Task/
just means "something that needs to get done," and it doesn't imply anything
regarding implementation in you hardware or software. We can illustrate
concurrency with the song "Telephone" by Lady Gaga. Gaga sings,

#+begin_quote
I cannot text you with a drink in my hand, eh
#+end_quote

Here, she's explaining that she can only manage one task (drinking). She
flat-out rejects the suggestion that she can manage more than one task. However,
if she decided to process tasks concurrently, she would sing,

#+begin_quote
I will put down this drink to text you, then put my phone away and continue
drinking. eh
#+end_quote

In this hypothetical universe, Lady Gaga is managing two tasks: drinking and
texting. However, she is not executing both tasks at the same time. Instead,
she's switching between the two, or /interleaving/. Note that, while
interleaving, you don't have to fully complete a task before switching: Gaga
could type one word, put down her phone, puck up her drink and take a sip, and
then switch back to her phone and type another word.

/Parallelism/ refers to executing more than one task at the same time. If Madame
Gaga were to execute her two tasks in parallel she would sing.

#+begin_quote
I can text you with one hand while I use the other to drink. eh
#+end_quote

Parallelism is a subclass of concurrency: before you execute multiple tasks
simultaneously, you first have to manage multiple task.

Clojure has many features that allow you to achieve parallelism easily. While
the Lady Gaga system achieves parallelism by simultaneously executing tasks on
multiple hands, computer systems generally achieve parallelism by simultaneously
executing tasks on multiple processors.

It's important to distinguish parallelism from /distribution/. Distributed
computing is a special version of parallel computing where the processors are in
different computers and tasks are distributed to computers over a network. It'd
be like Lady Gaga asking Beyonce, "Please text this guy while I drink." Although
you can do distributed programming in Clojure with the aid of libraries, this
book covers only parallel programming, and here I'll use /parallel/ to refer
only to [fn:2]cohabiting processors. If you're interested in distributed
programming, check out Kyle Kingsbury's /Call Me Maybe series at
https://aphyr.com/

** Blocking and Asynchronous Tasks

One of the major cases for concurrent programming is for /blocking/ operations.
Blocking really just means waiting for an operation to finish. You'll most often
hear it used in relation to I/O operations, like reading a file or waiting for
an HTTP request to finish. Let's examine this using the concurrent Lady Gaga
example.

If Lady Gaga text her interlocutor and then stands there with there phone in her
hand, staring at the screen for a response and not drinking, then you would say
that the /read next text message/ operation is blocking and that these tasks are
executing /synchronously/.

If, instead, she tucks her phone away so she can drink until it alerts her by
beeping or vibrating, then the /read text message/ task is not blocking and you
would say she's handling the task /asynchronously/.

** Concurrent Programming and Parallel Programming

Concurrent programming and parallel programming refer to techniques for
decomposing[fn:3] a task into subtasks that can execute in parallel and managing
the risks that arise when your program executes more than one task at the same
time. For the rest of the chapter, I'll use the two terms interchangeably
because the risk are pretty much the same for both.

To better understand those risks and how Clojure helps you avoid them, let's
examine how concurrency and parallelism are implemented in Clojure.

* Clojure Implementation: JVM Threads

I've been using the term /task/ in an abstract sense to refer a series of
related operations without regard for how a computer might implement the task
concept. For example, texting is a task that consist of a series of related
operations that are totally separate form the operations involved pouring a
drink into your face.

In Clojure, you can think of your normal, /serial/ code as sequence of tasks.
You indicate that tasks can be performed concurrently by placing them on JVM
/threads/.

** What’s a Thread?

I'm glad you asked! A thread is a subprogram. A program can have many threads,
and each thread executes its own set of instruction while enjoying shared access
to the program's state.

Thread management functionality can exist at multiple levels in a computer. For
example, the operating system kernel typically provides system calls to create
and manage threads. The JVM provides its own platform independent thread
management functionality, and since Clojure Programs run in the JVM, they use
JVM threads. You'll learn more about JVM in Chapter 12.

You can think of a thread as an actual, physical piece of thread that strings
together a sequence of instructions. In my mind, the instruction are
marshmallows, because marshmallows are delicious. The processor executes these
instructions in order. I picture this as an alligator consuming the
instructions, because alligators love marshmallows (true fact!). So executing a
program looks like a bunch of marshmallows strung out on a line with an
alligator traveling down the line and eating them one by one. Figure 9-1 shows
this model for a single-core processor executing a single-threaded program.

#+caption: Figure 9-1: Single-core processor executing a single threaded program
#+attr_latex: scale=0.75
#+label: fig:label
[[file:figures-listing-and-images/Figures-9-1.png]]

A thread can /spawn/ a new thread to execute tasks concurrently. In a
single-processor system, the processor switches back and forth between the
threads (interleaving). Here's where potential concurrency issues get
introduced. Although the processor executes the instructions on each thread in
order, it makes no guarantees about when it will switch back and forth between
threads.

Figure 9-2 shows illustration of two threads. A and B, and a timeline of how
their instruction of thread A.

#+caption: Figure 9-2: Single-core processor executing two threads
#+attr_latex: scale=0.75
#+label: fig:label
[[file:figures-listing-and-images/Figures-9-2.png]]

Note that this is just one possible order of instruction execution. The
processor could also have executed the instruction in the order A1, A2, A3, B1,
A4, B2, B3 for example. This makes the program /nondeterministic/. You can't
know beforehand what the result will be because you can't know the execution
order, and different execution orders can yield different results.

This example shows concurrent execution on a single processor through
interleaving, whereas a multi-core system assigns a thread to each core,
allowing the computer to execute more than one thread simultaneously. Each core
executes its thread's instruction in order, as shown in Figure 9-3.

#+caption: Figure 9-3: Two threads, two processors
#+attr_latex: scale=0.75
#+label: fig:label
[[file:figures-listing-and-images/Figures-9-3.png]]

As with interleaving on a single core, there are no guarantees for the overall
execution order, so the program is nondeterministic. When you add a second
thread to a program, it becomes nondeterministic, and this makes it possible for
your program to fall prey to three kinds of problem.

*** Here are key characteristics of threads:

. Lightweight Process:

  Threads are often described as "lightweight process" because they share
  resources like memory space and open file with other threads within the same
  process, but each thread has its own counter stack and set of register.

. Concurrency and Parallelism:

  Threads enable concurrency and, on multiple-core processor, true parallelism.
  This means a program can perform multiple operations seemingly simultaneously
  or actually at the same time, leading to improve responsiveness and
  efficiency.

. Shared Resources:

  Threads within the same process share the process's memory space, including
  global variables and heap memory. this allows for efficient communication
  between threads but also necessitates careful management to avoid race
  conditions and other concurrency issues.

. Independent Execution:

  Each thread executes a sequence of instructions independently. The operating
  system's scheduler manages the allocation of CPU time to different threads,
  switching between them rapidly to give the illusion of simultaneous execution.

. Multithreading:

  The use of multiple threads within a single program is know as multithreading.
  This is a common technique for building responsive user interfaces, handling
  multiple client requests in server applications, and performing
  computationally intensive task more quickly

** The Three Goblins: Reference Cells, Mutual Exclusion, and Dwarven Berserkers

There are three central challenges in concurrent programming, also known as the
three /The Concurrency Goblins/. To see why these are scary, imagine that the
program in the image in Figure 9-3 includes the pseudo-instruction in Table 9-1.

#+caption: Table 9-1: Instruction for a program with a Nondeterministic Outcome
#+attr_latex: scale=0.75
#+label: fig:label
[[file:figures-listing-and-images/Tables-9-1.png]]

If the processor follows the order A1, A2, A3, B1, B3, then /x/ will have a
value of /2/, as you'd expect. But if it follows the order A1, A2, B1, A3, B3,
/X/'s value will be /1/, as you can see in Figure 9-4.

#+caption: Table 9-4: Two threads interacting with a reference cell
#+attr_latex: scale=0.75
#+label: fig:label
[[file:figures-listing-and-images/Figures-9-4.png]]

We'll call this the */reference cell/* problem (the first Concurrency Goblin).
The reference cell problem occurs two threads can read and write to the same
location, and the value at the location depends on the order of the reads and
writes.

The second Concurrency Goblin is */mutual exclusion/*. Imagine two threads, each
trying to write a spell to a file. Without any way to claim exclusive write
access to the file, the spell will end up garbled because the write instructions
will be interleaved. Consider the following two spells:

#+begin_quote
 By the power invested in me
 by the state California,
 I now pronounce you man and wife

 Thunder, lightning, wind, and rain,
 a delicious sandwich, I summon again
#+end_quote

If you write these to a file without mutual exclusion, you could end up with
this:

#+begin_quote
By the power invested in me
by Thunder, lightning, wind, and rain,
the state of California
I now pronounce you a delicious man sandwich, and wife
I summon again
#+end_quote

The third Concurrency Goblin is what I'll call the /dwarven berseker/ problem
(aka /deadlock/). Imagine four berserkers sitting around a roughhewn. Circular
wooden table comforting each other. "I know I'm distant toward my children, but
I just don't know how to communicate with them," one growls. The rest sip their
coffee and nod knowingly, care lines creasing their eye places.

Now, as everyone knows, the dwarven berserker ritual for ending a comforting
coffee klatch is to pick up their "comfort sticks" (double-bladed war axes) and
scratch each other's backs. One war axe is placed between each pair of dwarves,
as shown in Figure 9-5.

Their ritual proceeds thusly:

1. Pick up the /left/ war axe, when available.
2. Pick up the /right/ war axe, when available.
3. Comfort your neighbor with vigorous swings of your "comfort sticks."
4. Release both war axes.
5. Repeat

#+caption: Table 9-5: Dwarven berserkers at a comforting coffee klatch
#+attr_latex: scale=0.75
#+label: fig:label
[[file:figures-listing-and-images/Figures-9-5.png]]

Following this ritual, it's entirely possible that all the dwarven berserkers
will pick up their left comfort stick and then block indefinitely while waiting
for the comfort stick to their right to become available, resulting in deadlock.
(By the way, if you want to look into this phenomenon further, it's usually
referred to as the /dining philosophers problem/, but that's a more boring
scenario.) This book doesn't discuss deadlock in much detail, but it's good to
know the concept and its terminology.

Concurrent programming has its goblins, but with the right tools, it's
manageable and even fun. Let's start looking at the right tools.

* Futures, Delays, and Promises

Futures, delays, and promises are easy, lightwight tools for concurrent
programming .In this section, you'll learn how each one works and how to use
them together to defend against the reference cell Concurrency Goblin and the
mutual exclusion Concurrency Goblin. You'll discover that, although simple,
these tools go a long way toward meeting your concurrency needs.

They do this by giving you more flexibility that is possible with serial code.
When you write serial code, you bind together these three events:

. Task definition
. Task execution
. Requiring the task's result

As an example, look at this hypothetical code, which defines a simple API call
task:

#+begin_src clojure :results value verbatim :exports both eval: never-export
(web-api/get: dwarven-beard-waxes)
#+end_src

#+RESULTS:

As soon as Clojure encounters this task definition, it executes it. It also
requires the result /right now/, blocking until the API call finishes. Part of
learning concurrent programming is learning to identify when these chronological
couplings aren't necessary. Futures, delays, and promises allows you to separate
task definition, task execution, and requiring the result. Onward!

** Futures

In Clojure, you can use /futures/ to define a task and places it on another
thread without requiring the result immediately. You can create a future withthe
future macro. Try this in REPL:

#+begin_src clojure :results value verbatim :exports both eval: never-export
  (future (Thread/sleep 400)
          (println "I'll print after 4 seconds"))
  (println "I'll print immediately")
#+end_src

/Thread/sleep/ tells the current thread to just on its bum and do nothing for
the specified number of milliseconds. Normally, if you evaluated /Thread/sleep/
in your REPL, you wouldn't be able to evaluate any other statement until the
REPL was done sleeping: the thread executing your REPL would be blocked.
However, /future/ creates a new thread and places each expression you pass it on
the new thread, including /Thread/sleep/, allowing the REPL's thread to
continue, unblocked.

You can use futures to run tasks on a separate thread and then forget about
them, but often you'll want to use the result of the task. The /future/ function
return a reference value that you can use to request the result. The reference
is like the ticket that a dry cleaner give you: at any time you can use it to
request your clean dress, but if you dress isn't clean yet, you'll have to wait.
Similarly, you can use the reference value to request at future's result, but if
the future isn't done computing the result, you'll have to wait.

*Requesting a future's result* is called /dereferencing/ the future, and you do
it with either the /deref/ function or the /@/ reader macro. A future's result
value is the value of the last expression evaluated in its body. A future's body
executes only once, and its value gets cached. Try the following:

#+begin_src clojure :results value verbatim :exports both eval: never-export
  (let [result (future (println "this prints once")
                       (+ 1 1))]
    (println "deref:" (deref result))
    (println "@: " @result))
  ;; => this prints once
  ;; => deref: 2
  ;; => @:  2
#+end_src

Notice that the string /"this prints once"/ indeed prints only once, even though
you dereference future twice. This shows that the future's body ran only one and
the result, /2/, got cached.

Dereferencing a future will block if the future hasn't finished running, like
so:

#+begin_src clojure :results value verbatim :exports both eval: never-export
  (let [result (future (Thread/sleep 3000)
                       (+ 1 1))]
    (println "the result is: " @result)
    (println "it will be at least 3 secomd before i print"))
  ;; =>  the result is:  2
  ;; =>  it will be at least 3 secomd before i print
#+end_src

Sometimes you want to place a time limit on how long to wait for a future. To do
that, you can pass a /deref/ a number of milliseconds to wait along with the
value to return if the /deref/ times out:

#+begin_src clojure :results value verbatim :exports both eval: never-export
  (deref (future (Thread/sleep 1000) 0) 10 5)
  ;; => 5
#+end_src

This code tells /deref/ to return the value /5/ if the future doesn't return a
value within 10 milliseconds.

Finally, you can interrogate a future using /realized?/ to see if it's done
running:

#+begin_src clojure :results value verbatim :exports both eval: never-export
  (realized? (future (Thread/sleep 1000)))
  ;; => false

  (let [f (future)]
    @f
    (realized? f))
  ;; =>true
#+end_src

Futures are a dead-simple way to sprinkle some concurrency on your program.

On their own, they give you the power to chuck task onto other threads, which
can make your more efficient. They also let your program behave more flexibly by
giving you control over when a task's result is required.

When you dereference a future, you indicate that the result is required /right
now/ that evaluation should stop until the result is obtained. You'll see how
this can help you deal with the mutual exclusion problem in just a bit.
Alternatively, you can ignore the result. For example, you can use futures to
write to a log fie asynchronously, in which case you don't need to dereference
the future to get any value back.

The flexibility that futures give you is very cool. Clojure also allows you to
When you treat a task definition and requiring the result independently with
When you delays and promises.

** Delays

/Delays/ allow you to define a task without having to execute it or require the
When you result immediately. You can create a delay using /delay/:

#+begin_src clojure :results value verbatim :exports both eval: never-export
  (def jackson-5-delay
    (delay (let [message "Just call my name and I'll be there"]
             (println "First deref:" message)
             message)))
#+end_src

In this example, nothing is printed, because we haven't yet asked the /let/form
to be evaluated. You can evaluate the delay and get its result by dereferencing
it or by using /force/. /force/ behaves identically to /deref/ in that it
communicates more clearly that you're causing task to start as opposed to
waiting for a task to finish:

#+begin_src clojure :results value verbatim :exports both eval: never-export
  (force jackson-5-delay)
  ;; =>  First deref: Just call my name and I'll be there
  ;; =>"Just call my name and I'll be there"
#+end_src

Like futures, delays is run only once and its result is cached. Subsequent
dereferencing will return Jackson 5 message without printing anything:

#+begin_src clojure :results value verbatim :exports both eval: never-export
  @jackson-5-delay
  ;; =>"Just call my name and I'll be there"
#+end_src

One way you can call a delay is to fire off statement the first time one future
out of a group of related futures finished. For example, pretend your app
uploads a set of headshots to a headshot-sharing site and notifies the owner as
soon as the first one is up, as in the following:

#+begin_src clojure :results value verbatim :exports both eval: never-export
  (def gimli-headshots ["serious.jpg" "fun.jpg" "playful.jpg"])
  (defn email-user
    [email-address]
    (println "Sending headshot notification to" email-address))
  (defn upload-document
    "Nedds to be impelemented"
    [headshot]
    true)
  (let [notify (delay (email-user "and-my-axe@gmail.com"))]  ;; [L-1]
    (doseq [headshot gimli-headshots]
      (future (upload-document headshot)
              (force notify)))) ;; [L-2]
#+end_src

In this example, you define a vector of headshot to upload /(gimli-headshots)/
and two functions (/email-user/ and /upload-document/) to pretend-perform the
two operations. Then you use /let/ to bind notify to a delay. The body of the
delay, /(email-user "and-my-axe@gmail.com")/ [L-1], isn't evaluated when the
delay is created. Instead, it gets evaluated the first time one of the futures
created by the /doseq/ form evaluates /(force notify)/ [L-2]. Even though
/(force notify)/ will be evaluated three times, the delay body is available so
he can begin tweaking it and sharing it. He'll also appreciate not being
spammed, and you'll appreciate not facing this dwarven wrath.

This techniques can help protect you from the mutual exclusion Concurrency
Goblin--the problem of making sure that only one thread can access a particular
resource at a time. In this example, the delay guard the email server resource.
Because the body of a delay is guaranteed to fire only once, you can be sure
that you will never run into a situation where two threads send the same email.
Of course, no thread will ever be able to use the delay to send an email again.
That might be too drastic a constaint for most situations, but it cases like
this example, it works perfectly.

** Promises

/Promises/ allow you to express that you expect a result without having to
define the task that should produce it or when that task should run. You create
promises using /promise/ using /promise/ and deliver a result to them using
/deliver/. You obtain the result by dereferencing:

#+begin_src clojure :results value verbatim :exports both eval: never-export
  (def my-promise (promise))
  (deliver my-promise (+ 1 2))
  @my-promise
  ;; => 3
#+end_src

Here, you create a promise and then deliver a value to it. Finally, you obtain
the value by dereferencing the promise. Dereferencing is how you express that
you expect a result, and if you had tried to dereference /my-promise/ without
first delivering a value, the program would block until a promise was delivered,
just like with futures and delays. You can only deliver a result to promise
once.

One use for promises is to find the first satisfactory element in a collection
of data. Suppose, for example, that you're gathering ingredients to make you
parrot sound like James Earl Jones. James Earl Jones has the smoothest voice on
earth, one of the ingredientsis premium yak butter with a smoothness rating of
97 or greater. You have a budget of $100 for one pound.

You are modern practitioner of the magicornithological arts, so rather than
tediously navigating each yak butter retail site, you create a script to give
you the URL of the firs yak butter that meets your needs.

The following code defines some yak butter products, creates a function to mock
up an API call, and creates another function to test whether a product is
satisfactory:

#+begin_src clojure :results value verbatim :exports both eval: never-export
  (def yak-butter-internatioal
    {:store "Yak Butter International"
     :price 90
     :smoothness 90})

  (def butter-than-nothing
    {:store "Butter Than Nothing"
     :price 150
     :smoothness 83})

  ;; This is the butter that meets our requirement
  (def baby-got-yak
    {:store "Baby Got Yak"
     :price 94
     :smoothness 99})

  (defn mock-api-call
    [result]
    (Thread/sleep 1000)
    result)

  (defn satisfactory?
    "If the butter meets our criteria, return the butter, else return false"
    [butter]
    (and (<= (:price butter) 100)
         (>= (:smoothness butter) 97)
         butter))
#+end_src

The API call waits one second before returning a result to simulate the time it
would take to perform an actual call.

To show how long it will take to check the sites synchronously, we'll use /some/
to apply the /satisfactory?/ function to each element of the collection and
return the first truthy result, or nil if there are none. When you check each
site synchronously, it could take more that one second per site to obtain a
result, as the following code shows:

#+begin_src clojure :results value verbatim :exports both eval: never-export
  (time (some (comp satisfactory? mock-api-call)
              [yak-butter-internatioal butter-than-nothing baby-got-yak]))

  ;; =? "Elapsed time: 3001.087355 msecs"
  ;; =>{:store "Baby Got Yak", :price 94, :smoothness 99}
#+end_src

Here I've used /comp/ to compose functions, and I've used /time/ to print the
time taken to evaluate a form. You can use a promise and futures to perform each
check on a separate threads. If your computer has multiple cores, this could
reduce the time it takes to about one second:

#+begin_src clojure :results value verbatim :exports both eval: never-export
  (time
   (let [butter-promise (promise)]
     (doseq [butter [yak-butter-internatioal butter-than-nothing baby-got-yak]]
       (future (if-let [satisfactory-butter (satisfactory? (mock-api-call butter))]
                 (deliver butter-promise satisfactory-butter))))
     (println "And the winner is:" @butter-promise)))

  ;; => And the winner is: {:store Baby Got Yak, :price 94, :smoothness 99}
  ;; => "Elapsed time: 1005.144373 msecs"

#+end_src

In this example, you first create a promise, /@butter-promise/, and then create
three futures with access to that promise. Each future's task is to evaluate a
yak butter site and to deliver the site's data to the promise if it's
satisfactory. Finally, you dereference /@butter-promise/, causing the program to
block until the site data is delivered.This takes about one second instead of
three because the site evaluations happen in parallel. By decoupling the
requirement for a result form how the result is actually computed, you can
perform multiple computations in parallel and save some time.

You can view this as a way to protect yourself from the reference cell
Concurrency Goblin. Because promises can be written to only once, you prevent
the kind of inconsistent state that arises from nondeterministic read and
writes.

You might be wondering what happens if none of the yak butter is satisfactory.
If that happens, the dereference would block forever and tie up the thread. To
avoid that, you can include a timeout:

#+begin_src clojure :results value verbatim :exports both eval: never-export
  (let [p (promise)]
    (deref p 100 "time out"))
#+end_src

This create a promise, /p/, and tires to dereference it. The number 100 tells
/deref/ to wait 100 milliseconds, and if no value is available by then, to use
the timeout value, /"time out"/.

The last detail I should mention is that you can also promises to register
callbacks, achieving the same functionality that you might be used to in
JavaScript. JavaScript callbacks are a way of defining code that should execute
asynchronously once some other code finishes. Here's how to do it in Clojure:

#+begin_src clojure :results value verbatim :exports both eval: never-export
  (let [ferengi-wisdom-promise (promise)]
    (future (println "Here's some Ferengi wisdom:" @ferengi-wisdom-promise))
    (Thread/sleep 100)
    (deliver ferengi-wisdom-promise "Whisper your way to success"))
  ;; =>  Here's some Ferengi wisdom: Whisper your way to success
  ;; =>#<Promise@229f728: "Whisper your way to success">
#+end_src

This example creates a future that begins executing immediately. However, the
future's threads is blocking because it's waiting for a value to be delivered to
/ferengi-wisdom-promise/. After 1000 milliseconds, you deliver the value and the
/println/ statement in the future runs.

Futures, delays, promises are great, simple ways to manage concurrency in your
application. In the next section, we'll look at one more fun way to keep your
concurrent application under control.

** Rolling Your Own Queue

So far you've look at some simple ways to combine futures, delays, and promises
to make your concurrent program a little safer. In this section, you'll use a
macro to combine futures and promises in slightly more complex manner. You might
not necessarily ever use this code, but it'll show the power of these modest
tools bit more. The macro will require you to hold runtime logic and macro
expansion logic in your head at the same time to understand what's going on: if
you get stuck, just skip ahead.

One characterstic The Three Concurrency Goblins have in common is that they all
involve task concurrently accessing a shared resources--a variable, a printer, a
dwarven war axe--in an uncoordinated way. If you want to ensure that only one
task will access a resource at a time, you can place the resource access portion
of a task on a queue that's executed serially. It's kind of like making a cake:
you and a friend can separately retrieve the ingredients (egg, flour, eye of
newt, what you have), but some steps you'll have to perform serially. You have
to prepare the batter before you put it in the oven. Figure 9-6 illustrate this
strategy:

#+caption: Table 9-6: Dividing tasks into a serial portion and a concurrent portion lets you safely make your code more efficient.
#+attr_latex: scale=0.75
#+label: fig:label
[[file:figures-listing-and-images/Figures-9-6.png]]

To implement the queuing macro, you'll pay homage to the British, because they
invented queues. You'll use a queue to ensure that the customary British
greeting "Ello, gov'na! Pip pip! Cheerio!" is delivered in the correct order.
This demonstration will involve an abudance of sleeping, so here's a macro to do
that more concisely:


#+begin_src clojure :results value verbatim :exports both eval: never-export
  (defmacro wait
    "Sleep `timeout` seconds before evaluating body"
    [timeout & body]
    `(do (Thread/sleep ~timeout) ~@body))
#+end_src

All this code is take whatever forms you give it and insert a call to
/Thread/sleep/ before them, all wrapped up in /do/.

The code in Listing 9-1 splits up into a concurrent portion and a serialized
portion:

#+caption: Listing 9-1: The expansion of an enqueue macro call
#+attr_latex: scale=0.75
#+label: listing
#+begin_src clojure :results value verbatim :exports both eval: never-export
  (let [saying3 (promise)]
    (future (deliver saying3 (wait 100 "Cheerio")))
    @(let [saying2 (promise)]
       (future (deliver saying2 (wait 400 "Pip Pip!")))
       @(let [saying1 (promise)]  ;; [L-1]
          (future (deliver saying1 (wait 200 "Ello, gov'na!")))
          (println @saying1)
          saying1)
       (println @saying2)
       saying2)
    (println @saying3)
    saying3)
#+end_src

The overall strategy is to create a promise for each task (in this case,
printing part of the greeting) to create a corresponding future that will
deliver a concurrently computed value to the promise. This ensures that all of
the futures are created before any of the promises are dereferenced, and it
ensures that the serialized portions are executed in the correct order. The
value of /saying1/ is printed first--/"'Ello, gov'na!"/--then the value of
/saying2/, and finally /saying3/. Returning /saying1/ in a /let/ block and
dereferencing the /let/ block at [L-1] ensures that you'll be completely
finished with /saying1/ before the code moves on to do anything to /saying2/,
and this pattern is repeated with /saying2/ and /saying3/.

It might seem silly to dereference the /let/ block, but doing so lets you
abstract this code with a macro. And you will definitely want to use a macro
because writing out code like the previous example would drive you mental (as
the British would say). Ideally, the macro would work as shown in Listing 9-2:

#+caption: Listing 9-2: This os how you'd use enqueue
#+attr_latex: scale=0.75
#+label: listing
#+begin_src clojure :results value verbatim :exports both eval: never-export
  (-> (enqueue saying  ;; [L-1]
               (wait 200 "'Ello, gov'na!") ;; [L-2]
               (println @saying))  ;; [L-3]
      (enqueue saying (wait 400 "Pip pip!") (println @saying))  ;; [L-4]
      (enqueue saying (wait 100 "Cheerio!") (println @saying)))
#+end_src

The macro lets you name the promise that gets created [L-1], define how to
derive the value to deliver that promise [L-2], and define what to do with the
promise [L-3]. The macro can also take another /enqueue/ macro call as its first
argument, which lets you thread it [L-4]. Listing 9-3 shows how you can define
the /enqueue/ macro. After defining /enqueue/, the code in Listing 9-2 will
expand into the code in Listing 9-1, with all the nested /let/ expression:

#+caption: Listing 9-3: enqueue's implementation
#+attr_latex: scale=0.75
#+label: listing
#+begin_src clojure :results value verbatim :exports both eval: never-export
  (defmacro enqueue
    ([q concurrent-promise-name concurrent serialized]  ;; [L-1]
     `(let [~concurrent-promise-name (promise)]  ;; [L-2]
        (future (deliver ~concurrent-promise-name ~concurrent))
        (deref ~q)  ;; [L-3]
        ~serialized
        ~concurrent-promise-name))
    ([concurrent-promise-name concurrent serialized]  ;; [L-4]
     `(enqueue (future) ~concurrent-promise-name ~concurrent ~serialized)))
#+end_src

Notice first that this macro has two arities in order to supply a default value.
The first arity [L-1] is where the real work is done. it has the parameter /q/,
and the second arity does not. The second arity [L-4] calls the first with value
/(future)/ supplied for /q/; you'll see why in minute. At [L-2], the macro
returns a form that creates a promise, delivers its value in a future,
dereferences whatever form is supplied for /q/, evaluates the serialized code,
and finally returns the promise, /q/ will usually be a nested /let/ expression
returned by another call to /enqueue/, like in Listing 9-2. If no value is
supplied for /q/, the macro supplies a future so that the /deref/ at [L-3]
doesn't cause exception.

Now that we've written the /enqueue/ macro, let's try it out to see whether it
reduces the execution time:

#+begin_src clojure :results value verbatim :exports both eval: never-export
  (time @(-> (enqueue saying (wait 200 "'Ello, gov'na!") (println @saying))
             (enqueue saying (wait 400 "Pip pip!") (println @saying))
             (enqueue saying (wait 100 "Cheerio!")(println @saying))))
  ;; 'Ello, gov'na!
  ;; Pip pip!
  ;; Cheerio!
  ;; "Elapsed time: 401.789686 msecs"
#+end_src

* Summary

It's important for programmers like you to learn concurrent and parallel
programming techniques so you can design programs that run efficiently on modern
hardware. Concurrency refers to a program's ability to carry out more than one
task, and in Clojure you achieve this by placing tasks on separate threads.
Program execute in parallel when a computer has more than one CPU, which allows
more than one thread to be executed at the same time.

Concurrent programming refers to the techniques used to manage three concurrency
risks: *reference cells*, *mutual exclusion*, and *deadlock*. Clojure give you
three basic tools that help you mitigate those risks: /futures/, /delays/, and
/promises/. Each tool lets you decouple the three events of defining task,
executing a task, and requiring a task's result. Futures let you define a task
and execute it immediately, allowing you to require the result later or never.
Futures also cache their result. Delays let you define a task that doesn't get
executed until later, and a delay's result get cached. Promises let you express
that you require a result without having to know about the task that produces
that result. You can only deliver a value to a promise once.

In the next chapter, you'll explore the philosophical side of concurrent
programming and learn more sophisticated tools for managing the risks.

* Exercises

1. Write a function that takes a string as an argument and searches for it on
   Bing and Google using the /slurp/ function. You should return the HTML of the
   first page returned by the search.

2. update your function so it takes a second argument consisting of the search engines to use.

3. Create a new function that takes a search term and search engines as
   arguments, and returns a vector of the URLs form the firs page of search
   results from each search engine.

* Footnotes

[fn:3] The process of breaking down a complex problem or system into smaller,
more manageable parts to make it easier to understand, design, and solve.

[fn:2] to live together in a shared domestic space.

[fn:1] serious and immediately danger
